{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a quant strategy\n",
    "\n",
    "quant_strategy = None\n",
    "\n",
    "if quant_strategy is None:\n",
    "    bnb_config = None\n",
    "elif quant_strategy == \"8bit\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "    )\n",
    "elif quant_strategy == \"4bit\":\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAGMultiModalModel\n",
    "model = RAGMultiModalModel.from_pretrained(\"vidore/colqwen2-v1.0\", quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get everyone's favourite paper in here\n",
    "!wget https://arxiv.org/pdf/1706.03762\n",
    "!mkdir docs\n",
    "!mv 1706.03762 docs/attention.pdf\n",
    "!cp -r docs/attention.pdf docs/attention_with_a_mustache.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 12 of document 3 to index.\n"
     ]
    }
   ],
   "source": [
    "# Test indexing\n",
    "metadata = [{\"filename\":file_name} for file_name in os.listdir(\"docs\")]\n",
    "\n",
    "index_name = \"attention_index\"\n",
    "model.index(\n",
    "    input_path=Path(\"docs/\"),\n",
    "    index_name=index_name,\n",
    "    store_collection_with_index=False,\n",
    "    metadata=metadata,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# BLEU tables are on page 8 and 9. We've indexed the pdf and its evil mustached twin, so we should see similar scores occur twice for every relevant page.\n",
    "query = \"what's the BLEU score of this new strange method?\"\n",
    "results = model.search(query, k=5)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "\n",
    "print(\"Test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model.search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the index now, to ensure the results are still the same.\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model = RAGMultiModalModel.from_index(\"attention_index\", quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.search(query, k=5)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER BASED ON METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.search(query, k=5,filter_metadata={\"filename\":\"attention.pdf\"})\n",
    "\n",
    "print(\"Metadata information: \",model.model.doc_id_to_metadata)\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "   print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how it looks like with the collection stored with the index, for simpler VLM integration at the cost of memory/storage.\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\", quantization_config=bnb_config)\n",
    "\n",
    "# Test having base64 in the collection for completely seamless RAG.\n",
    "pdf_path = Path(\"docs/attention.pdf\")\n",
    "\n",
    "# Test indexing\n",
    "index_name = \"attention_index_with_collection\"\n",
    "model.index(\n",
    "    input_path=pdf_path,\n",
    "    index_name=index_name,\n",
    "    store_collection_with_index=True,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Test searching\n",
    "# page 6 holds the answer\n",
    "query = \"How does the positional encoding thing work?\"\n",
    "results = model.search(query, k=3)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "base_64s = set()\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "    print(f\"Base64: {result.base64[:50]}...\")\n",
    "    assert result.base64 not in base_64s\n",
    "    print(\"Base64 is unique!\")\n",
    "    base_64s.add(result.base64)\n",
    "print(\"Test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Now, let's add another document, which in this case is the same document, but we don't need to tell the model that!\n",
    "\n",
    "model.add_to_index(pdf_path, store_collection_with_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.search(query, k=3)\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "    print(f\"Base64: {result.base64[:50]}...\")\n",
    "print(\"Test completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
