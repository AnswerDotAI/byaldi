{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/recoverx/.pyenv/versions/3.11.3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/recoverx/.pyenv/versions/3.11.3/lib/python3.11/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 10.68it/s]\n",
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "# os.environ[\"HF_TOKEN\"] = \"YOUR_HF_TOKEN\"\n",
    "\n",
    "# Initialize RAGMultiModalModel\n",
    "model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-05 14:56:31--  https://arxiv.org/pdf/1706.03762\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.3.42, 151.101.131.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2215244 (2.1M) [application/pdf]\n",
      "Saving to: ‘1706.03762’\n",
      "\n",
      "1706.03762          100%[===================>]   2.11M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2024-09-05 14:56:32 (32.9 MB/s) - ‘1706.03762’ saved [2215244/2215244]\n",
      "\n",
      "mkdir: cannot create directory ‘docs’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Let's get everyone's favourite paper in here\n",
    "!wget https://arxiv.org/pdf/1706.03762\n",
    "!mkdir docs\n",
    "!mv 1706.03762 docs/attention.pdf\n",
    "!cp -r docs/attention.pdf docs/attention_with_a_mustache.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index attention_index to build a new one.\n",
      "Indexing file: docs/attention.pdf\n",
      "Added page 1 of document 0 to index.\n",
      "Added page 2 of document 0 to index.\n",
      "Added page 3 of document 0 to index.\n",
      "Added page 4 of document 0 to index.\n",
      "Added page 5 of document 0 to index.\n",
      "Added page 6 of document 0 to index.\n",
      "Added page 7 of document 0 to index.\n",
      "Added page 8 of document 0 to index.\n",
      "Added page 9 of document 0 to index.\n",
      "Added page 10 of document 0 to index.\n",
      "Added page 11 of document 0 to index.\n",
      "Added page 12 of document 0 to index.\n",
      "Added page 13 of document 0 to index.\n",
      "Added page 14 of document 0 to index.\n",
      "Added page 15 of document 0 to index.\n",
      "Index exported to .byaldi/attention_index\n",
      "Indexing file: docs/attention_with_a_mustache.pdf\n",
      "Added page 1 of document 1 to index.\n",
      "Added page 2 of document 1 to index.\n",
      "Added page 3 of document 1 to index.\n",
      "Added page 4 of document 1 to index.\n",
      "Added page 5 of document 1 to index.\n",
      "Added page 6 of document 1 to index.\n",
      "Added page 7 of document 1 to index.\n",
      "Added page 8 of document 1 to index.\n",
      "Added page 9 of document 1 to index.\n",
      "Added page 10 of document 1 to index.\n",
      "Added page 11 of document 1 to index.\n",
      "Added page 12 of document 1 to index.\n",
      "Added page 13 of document 1 to index.\n",
      "Added page 14 of document 1 to index.\n",
      "Added page 15 of document 1 to index.\n",
      "Index exported to .byaldi/attention_index\n",
      "Index exported to .byaldi/attention_index\n",
      "Search results for 'what's the BLEU score of this new strange method?':\n",
      "Doc ID: 1, Page: 8, Score: 19.375\n",
      "Doc ID: 1, Page: 9, Score: 19.375\n",
      "Doc ID: 0, Page: 8, Score: 19.375\n",
      "Doc ID: 0, Page: 9, Score: 19.375\n",
      "Doc ID: 1, Page: 11, Score: 17.75\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test indexing\n",
    "metadata = [{\"filename\":file_name} for file_name in os.listdir(\"docs\")]\n",
    "\n",
    "index_name = \"attention_index\"\n",
    "model.index(\n",
    "    input_path=Path(\"docs/\"),\n",
    "    index_name=index_name,\n",
    "    store_collection_with_index=False,\n",
    "    metadata=metadata,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# BLEU tables are on page 8 and 9. We've indexed the pdf and its evil mustached twin, so we should see similar scores occur twice for every relevant page.\n",
    "query = \"what's the BLEU score of this new strange method?\"\n",
    "results = model.search(query, k=5)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "\n",
    "print(\"Test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.8 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model.search(query, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 17.65it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Let's load the index now, to ensure the results are still the same.\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model = RAGMultiModalModel.from_index(\"attention_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'what's the BLEU score of this new strange method?':\n",
      "Doc ID: 0, Page: 1, Score: 19.875\n",
      "Doc ID: 3, Page: 8, Score: 19.75\n",
      "Doc ID: 4, Page: 8, Score: 19.75\n",
      "Doc ID: 3, Page: 9, Score: 19.125\n",
      "Doc ID: 4, Page: 9, Score: 19.125\n"
     ]
    }
   ],
   "source": [
    "results = model.search(query, k=5)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FILTER BASED ON METADATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata information:  {0: {'filename': 'attention_table.png'}, 1: {'filename': 'product_c.png'}, 2: {'filename': 'financial_report.pdf'}, 3: {'filename': 'attention_with_a_mustache.pdf'}, 4: {'filename': 'attention.pdf'}}\n",
      "Search results for 'what's the BLEU score of this new strange method?':\n",
      "Doc ID: 4, Page: 8, Score: 19.75\n",
      "Doc ID: 4, Page: 9, Score: 19.125\n",
      "Doc ID: 4, Page: 1, Score: 17.125\n",
      "Doc ID: 4, Page: 7, Score: 17.0\n",
      "Doc ID: 4, Page: 11, Score: 16.75\n"
     ]
    }
   ],
   "source": [
    "results = model.search(query, k=5,filter_metadata={\"filename\":\"attention.pdf\"})\n",
    "\n",
    "print(\"Metadata information: \",model.model.doc_id_to_metadata)\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "   print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8348433a1844561a4fe6a2300b0b54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index attention_index_with_collection to build a new one.\n",
      "Added page 1 of document 0 to index.\n",
      "Added page 2 of document 0 to index.\n",
      "Added page 3 of document 0 to index.\n",
      "Added page 4 of document 0 to index.\n",
      "Added page 5 of document 0 to index.\n",
      "Added page 6 of document 0 to index.\n",
      "Added page 7 of document 0 to index.\n",
      "Added page 8 of document 0 to index.\n",
      "Added page 9 of document 0 to index.\n",
      "Added page 10 of document 0 to index.\n",
      "Added page 11 of document 0 to index.\n",
      "Added page 12 of document 0 to index.\n",
      "Added page 13 of document 0 to index.\n",
      "Added page 14 of document 0 to index.\n",
      "Added page 15 of document 0 to index.\n",
      "Index exported to .byaldi/attention_index_with_collection\n",
      "Index exported to .byaldi/attention_index_with_collection\n",
      "Search results for 'How does the positional encoding thing work?':\n",
      "Doc ID: 0, Page: 6, Score: 18.875\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Base64 is unique!\n",
      "Doc ID: 0, Page: 3, Score: 18.625\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Base64 is unique!\n",
      "Doc ID: 0, Page: 9, Score: 17.5\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Base64 is unique!\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Let's see how it looks like with the collection stored with the index, for simpler VLM integration at the cost of memory/storage.\n",
    "from pathlib import Path\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
    "\n",
    "# Test having base64 in the collection for completely seamless RAG.\n",
    "pdf_path = Path(\"docs/attention.pdf\")\n",
    "\n",
    "# Test indexing\n",
    "index_name = \"attention_index_with_collection\"\n",
    "model.index(\n",
    "    input_path=pdf_path,\n",
    "    index_name=index_name,\n",
    "    store_collection_with_index=True,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Test searching\n",
    "# page 6 holds the answer\n",
    "query = \"How does the positional encoding thing work?\"\n",
    "results = model.search(query, k=3)\n",
    "\n",
    "print(f\"Search results for '{query}':\")\n",
    "base_64s = set()\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "    print(f\"Base64: {result.base64[:50]}...\")\n",
    "    assert result.base64 not in base_64s\n",
    "    print(\"Base64 is unique!\")\n",
    "    base_64s.add(result.base64)\n",
    "print(\"Test completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added page 1 of document 1 to index.\n",
      "Added page 2 of document 1 to index.\n",
      "Added page 3 of document 1 to index.\n",
      "Added page 4 of document 1 to index.\n",
      "Added page 5 of document 1 to index.\n",
      "Added page 6 of document 1 to index.\n",
      "Added page 7 of document 1 to index.\n",
      "Added page 8 of document 1 to index.\n",
      "Added page 9 of document 1 to index.\n",
      "Added page 10 of document 1 to index.\n",
      "Added page 11 of document 1 to index.\n",
      "Added page 12 of document 1 to index.\n",
      "Added page 13 of document 1 to index.\n",
      "Added page 14 of document 1 to index.\n",
      "Added page 15 of document 1 to index.\n",
      "Index exported to .byaldi/attention_index_with_collection\n"
     ]
    }
   ],
   "source": [
    "#  Now, let's add another document, which in this case is the same document, but we don't need to tell the model that!\n",
    "\n",
    "model.add_to_index(pdf_path, store_collection_with_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for 'How does the positional encoding thing work?':\n",
      "Doc ID: 1, Page: 6, Score: 18.875\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Doc ID: 0, Page: 6, Score: 18.875\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Doc ID: 0, Page: 3, Score: 18.625\n",
      "Base64: iVBORw0KGgoAAAANSUhEUgAABqQAAAiYCAIAAAA+NVHkAAEAAE...\n",
      "Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "results = model.search(query, k=3)\n",
    "print(f\"Search results for '{query}':\")\n",
    "for result in results:\n",
    "    print(f\"Doc ID: {result.doc_id}, Page: {result.page_num}, Score: {result.score}\")\n",
    "    print(f\"Base64: {result.base64[:50]}...\")\n",
    "print(\"Test completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
